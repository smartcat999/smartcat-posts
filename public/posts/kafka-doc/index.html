<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Smartcat&#39;s Blog</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="[TOC]
1 kafka connector管理 1.1 创建kafka connector apiVersion: kafka.strimzi.io/v1beta2 kind: KafkaConnect metadata: name: my-connect-cluster # connector名字 annotations: strimzi.io/use-connector-resources: &#34;true&#34; # 是否使用connector spec: replicas: 3 # 副本数 authentication: # connect使用的认证方式 type: tls certificateAndKey: certificate: source.crt key: source.key secretName: my-user-source bootstrapServers: my-cluster-kafka-bootstrap:9092 # kafka的server地址 tls: trustedCertificates: - secretName: my-cluster-cluster-cert # 连接集群所用secret证书的名字 certificate: ca.crt config: # connect配置 group.id: my-connect-cluster offset.storage.topic: my-connect-cluster-offsets config.storage.topic: my-connect-cluster-configs status.storage.topic: my-connect-cluster-status key.converter: org.apache.kafka.connect.json.JsonConverter value.converter: org.apache.kafka.connect.json.JsonConverter key.converter.schemas.enable: true value.converter.schemas.enable: true config.">
    <meta name="generator" content="Hugo 0.104.3" />
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="" />
<meta property="og:description" content="[TOC]
1 kafka connector管理 1.1 创建kafka connector apiVersion: kafka.strimzi.io/v1beta2 kind: KafkaConnect metadata: name: my-connect-cluster # connector名字 annotations: strimzi.io/use-connector-resources: &#34;true&#34; # 是否使用connector spec: replicas: 3 # 副本数 authentication: # connect使用的认证方式 type: tls certificateAndKey: certificate: source.crt key: source.key secretName: my-user-source bootstrapServers: my-cluster-kafka-bootstrap:9092 # kafka的server地址 tls: trustedCertificates: - secretName: my-cluster-cluster-cert # 连接集群所用secret证书的名字 certificate: ca.crt config: # connect配置 group.id: my-connect-cluster offset.storage.topic: my-connect-cluster-offsets config.storage.topic: my-connect-cluster-configs status.storage.topic: my-connect-cluster-status key.converter: org.apache.kafka.connect.json.JsonConverter value.converter: org.apache.kafka.connect.json.JsonConverter key.converter.schemas.enable: true value.converter.schemas.enable: true config." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/posts/kafka-doc/" /><meta property="article:section" content="posts" />



<meta itemprop="name" content="">
<meta itemprop="description" content="[TOC]
1 kafka connector管理 1.1 创建kafka connector apiVersion: kafka.strimzi.io/v1beta2 kind: KafkaConnect metadata: name: my-connect-cluster # connector名字 annotations: strimzi.io/use-connector-resources: &#34;true&#34; # 是否使用connector spec: replicas: 3 # 副本数 authentication: # connect使用的认证方式 type: tls certificateAndKey: certificate: source.crt key: source.key secretName: my-user-source bootstrapServers: my-cluster-kafka-bootstrap:9092 # kafka的server地址 tls: trustedCertificates: - secretName: my-cluster-cluster-cert # 连接集群所用secret证书的名字 certificate: ca.crt config: # connect配置 group.id: my-connect-cluster offset.storage.topic: my-connect-cluster-offsets config.storage.topic: my-connect-cluster-configs status.storage.topic: my-connect-cluster-status key.converter: org.apache.kafka.connect.json.JsonConverter value.converter: org.apache.kafka.connect.json.JsonConverter key.converter.schemas.enable: true value.converter.schemas.enable: true config.">

<meta itemprop="wordCount" content="465">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="[TOC]
1 kafka connector管理 1.1 创建kafka connector apiVersion: kafka.strimzi.io/v1beta2 kind: KafkaConnect metadata: name: my-connect-cluster # connector名字 annotations: strimzi.io/use-connector-resources: &#34;true&#34; # 是否使用connector spec: replicas: 3 # 副本数 authentication: # connect使用的认证方式 type: tls certificateAndKey: certificate: source.crt key: source.key secretName: my-user-source bootstrapServers: my-cluster-kafka-bootstrap:9092 # kafka的server地址 tls: trustedCertificates: - secretName: my-cluster-cluster-cert # 连接集群所用secret证书的名字 certificate: ca.crt config: # connect配置 group.id: my-connect-cluster offset.storage.topic: my-connect-cluster-offsets config.storage.topic: my-connect-cluster-configs status.storage.topic: my-connect-cluster-status key.converter: org.apache.kafka.connect.json.JsonConverter value.converter: org.apache.kafka.connect.json.JsonConverter key.converter.schemas.enable: true value.converter.schemas.enable: true config."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Smartcat&#39;s Blog
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1"></h1>
      
      
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>[TOC]</p>
<h4 id="1-kafka-connector管理">1 kafka connector管理</h4>
<h5 id="11-创建kafka-connector">1.1 创建kafka connector</h5>
<pre tabindex="0"><code>apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnect
metadata:
  name: my-connect-cluster  # connector名字
  annotations:
    strimzi.io/use-connector-resources: &#34;true&#34; # 是否使用connector
spec:
  replicas: 3 # 副本数
  authentication: # connect使用的认证方式
    type: tls
    certificateAndKey:
      certificate: source.crt
      key: source.key
      secretName: my-user-source
  bootstrapServers: my-cluster-kafka-bootstrap:9092 # kafka的server地址
  tls: 
    trustedCertificates:
      - secretName: my-cluster-cluster-cert  # 连接集群所用secret证书的名字
        certificate: ca.crt
  config: # connect配置
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  resources: # pod的资源配置
    requests:
      cpu: &#34;1&#34;
      memory: 2Gi
    limits:
      cpu: &#34;2&#34;
      memory: 2Gi
  logging: # 日志配置
    type: inline
    loggers:
      log4j.rootLogger: &#34;INFO&#34;
  readinessProbe: # pod是否read检测
    initialDelaySeconds: 15
    timeoutSeconds: 5
  livenessProbe: # pod是否存活检测
    initialDelaySeconds: 15
    timeoutSeconds: 5
  jvmOptions: # 运行jvm配置
    &#34;-Xmx&#34;: &#34;1g&#34;
    &#34;-Xms&#34;: &#34;1g&#34;
  template: # pod的template配置
    pod:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: application
                    operator: In
                    values:
                      - postgresql
                      - mongodb
              topologyKey: &#34;kubernetes.io/hostname&#34;
    connectContainer: # Jaeger tracer配置
      env:
        - name: JAEGER_SERVICE_NAME
          value: my-jaeger-service
        - name: JAEGER_AGENT_HOST
          value: jaeger-agent-name
        - name: JAEGER_AGENT_PORT
          value: &#34;6831&#34;
</code></pre><p>说明：</p>
<ul>
<li>tls字段表示连接broker集群所有的证书的secret，secret的默认名字是{CLUSTER-NAME}-cluster-cert，authentication表示connect使用的认证方式，用来连接connect的。</li>
</ul>
<h5 id="12-修改connect配置">1.2 修改connect配置</h5>
<p>只需要修改spec.config字段，既可以修改connect的配置</p>
<pre tabindex="0"><code>spec:
  config: 
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
</code></pre><p>config的具体配置参见https://kafka.apache.org/documentation/#connectconfigs</p>
<h5 id="13-删除connect">1.3 删除connect</h5>
<p>删除connect对应的cr资源即可</p>
<pre tabindex="0"><code>kubectl delete kafkaconnect CONNECT-NAME -n NAMESPACE
</code></pre><h4 id="2-user管理">2 user管理</h4>
<h5 id="21-创建user资源">2.1 创建user资源</h5>
<p>kafkauser资源只有在认证模式为scram-sha-512或者tls时才会生效</p>
<pre tabindex="0"><code>apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaUser 
metadata:
  name: saas  # 用户名称
  labels:
    strimzi.io/cluster: my-cluster  # kafka集群名字
spec:
  authentication:
    type: scram-sha-512  # 认证方式，和集群中端口的认证方式对应
  authorization:
    type: simple  # 授权方式，采用默认值即可
    acls:
      # Example consumer Acls for topic my-topic using consumer group my-group
      - resource:  # 资源做权限控制
          type: topic  #  资源类型，存在多种资源类型，参看https://wiki.yunify.com/pages/viewpage.action?pageId=128423310
          name: my-topic # 资源名称
          patternType: literal # 匹配模式
        operation: Read # 权限
        host: &#34;*&#34; # 作用的ip
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: &#34;*&#34;
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read
        host: &#34;*&#34;
      # Example Producer Acls for topic my-topic
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Write
        host: &#34;*&#34;
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Create
        host: &#34;*&#34;
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: &#34;*&#34;
</code></pre><h5 id="22-修改user资源中acl">2.2 修改user资源中acl</h5>
<p>修改spec.authorization.acls字段即可</p>
<pre tabindex="0"><code>spec:
  authorization:
    acls:
      # Example consumer Acls for topic my-topic using consumer group my-group
      - resource:  # 资源做权限控制
          type: topic  #  资源类型，存在多种资源类型，参看https://kafka.apache.org/documentation/#security_authz_cli
          name: my-topic # 资源名称
          patternType: literal # 匹配模式
        operation: Read # 权限
        host: &#34;*&#34; # 作用的ip
</code></pre><h5 id="23-修改user资源中的密码">2.3 修改user资源中的密码</h5>
<p>修改密码的操作，只能在当认证方式为scram-sha-512时，通过创建自定义的secret，然后按照下面方式将值传递给password。注意secret中关于的密码的值需要经过base64编码。</p>
<pre tabindex="0"><code>spec:
  authentication:
    type: scram-sha-512
    password:
      valueFrom:
        secretKeyRef:
          name: my-secret 
          key: my-password 
</code></pre><h5 id="24-查看对应用户的信息">2.4 查看对应用户的信息</h5>
<p>创建用户之后，在当前namespace下面会出现对应用户的secret，查看对应的secret即可。其中password这一行的值是经过base64编码之后的结果。</p>
<p>##删除用户资源</p>
<p>直接删除对应的cr资源即可</p>
<pre tabindex="0"><code>kubectl delete kafkauser USER_NAME -n NAMESPACE
</code></pre><h4 id="3-kafka-topic管理">3 kafka topic管理</h4>
<h5 id="31-创建topic资源">3.1 创建topic资源</h5>
<pre tabindex="0"><code>apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: my-topic2  # topic名字
  labels:
    strimzi.io/cluster: &#34;my-cluster&#34;  # 对应集群名字
spec:
  partitions: 3  # partition的数目
  replicas: 1 # 副本数目
  config: # topic的其它配置
    retention.ms: 7200000
    segment.bytes: 1073741824
</code></pre><h5 id="32-修改topic资源">3.2 修改topic资源</h5>
<p>修改 spec →config、spec →partitions和spec→replicas</p>
<pre tabindex="0"><code>spec:
 partitions: 3  # 分区数
 replicas: 1  # 副本数
 config:  # 其它参数配置
   retention.ms: 7200000
   segment.bytes: 1073741824
</code></pre><p>config中的具体参数值可以参见https://kafka.apache.org/documentation/#topicconfigs</p>
<h5 id="33-删除topic资源">3.3 删除topic资源</h5>
<p>直接删除对应cr资源即可，如下命令</p>
<pre tabindex="0"><code>kebectl delete kafkatopic TOPIC_NAME -n NAMESPACE
</code></pre><ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://example.org/" >
    &copy;  Smartcat's Blog 2022 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
